{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TransferLearning-w/oRandomDA.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdLm23di7Djr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from google.colab import drive\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOf1ZT6c7H0X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "bbe82886-e195-4cd8-ba35-2ab3f37873c7"
      },
      "source": [
        "tfds.disable_progress_bar()\n",
        "\n",
        "train_ds, validation_ds, test_ds = tfds.load(\n",
        "    \"cats_vs_dogs\",\n",
        "    # Reserve 10% for validation and 10% for test\n",
        "    split=[\"train[:40%]\", \"train[40%:50%]\", \"train[50%:60%]\"],\n",
        "    as_supervised=True,  # Include labels\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1mDownloading and preparing dataset cats_vs_dogs/4.0.0 (download: 786.68 MiB, generated: Unknown size, total: 786.68 MiB) to /root/tensorflow_datasets/cats_vs_dogs/4.0.0...\u001b[0m\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/urllib3/connectionpool.py:847: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
            "  InsecureRequestWarning)\n",
            "WARNING:absl:1738 images were corrupted and were skipped\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Shuffling and writing examples to /root/tensorflow_datasets/cats_vs_dogs/4.0.0.incomplete0TYX6V/cats_vs_dogs-train.tfrecord\n",
            "\u001b[1mDataset cats_vs_dogs downloaded and prepared to /root/tensorflow_datasets/cats_vs_dogs/4.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHlGyMDC7hGk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "c0e02c33-b09d-4035-ce4f-7f612b406be3"
      },
      "source": [
        "drive.mount('/content/gdrive')\n",
        "path = \"/content/gdrive/My Drive/colab/training_2/tfjs_cat_dog\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmpfMP2n7KER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "size = (224, 224)\n",
        "BFS = 10\n",
        "BTS = 32\n",
        "\n",
        "train2_ds = train_ds.map(lambda x, y: (tf.image.resize(x, size), y ))\n",
        "val2_ds = validation_ds.map(lambda x, y: (tf.image.resize(x, size), y ))\n",
        "test2_ds = test_ds.map(lambda x, y: (tf.image.resize(x, size), y ))\n",
        "\n",
        "train2_ds = train2_ds.cache().batch(BTS).prefetch(buffer_size=BFS)\n",
        "val2_ds = val2_ds.cache().batch(BTS).prefetch(buffer_size=BFS)\n",
        "test2_ds = test2_ds.cache().batch(BTS).prefetch(buffer_size=BFS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH3BC4UH7SKp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint_path = \"/content/gdrive/My Drive/colab/training_2/cp.ckpt\"\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh0EJC2YSPoe",
        "colab_type": "text"
      },
      "source": [
        "## Use a Sequential Model to be able to use with TensorFlowJS\n",
        "\n",
        "For a comparison of different CNN-architecture see [this explanation](https://www.kaggle.com/shivamb/cnn-architectures-vgg-resnet-inception-tl#1.4-Resnets).\n",
        "Due to its simple linear series of layers, VGG is the only net I was able to use with TFJS.\n",
        "Xception, MobileNet, ResNet and Inception all contain some parallel processing parts which is why they cannot be disassembled and recomposed as needed for the creation of a Sequential model which is readable in TFJS.\n",
        "\n",
        "From the [documentation](https://keras.io/guides/sequential_model/#transfer-learning-with-a-sequential-model):\n",
        ">A Sequential model is not appropriate when:\n",
        "\n",
        ">    - Your model has multiple inputs or multiple outputs\n",
        ">   - Any of your layers has multiple inputs or multiple outputs\n",
        ">    - You need to do layer sharing\n",
        ">    - You want non-linear topology (e.g. a residual connection, a multi-branch model)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPDxCB-8GxH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d6e5a013-b162-4598-8883-249e52c3ea33"
      },
      "source": [
        "\n",
        "b_model = keras.applications.VGG19(\n",
        "    weights=\"imagenet\",\n",
        "    input_shape=(224, 224, 3),\n",
        "    include_top=False,\n",
        ") \n",
        "\n",
        "# Freeze the base_model\n",
        "b_model.trainable = False\n",
        "layers = b_model.layers\n",
        "model2 = keras.Sequential()\n",
        "model2.add(keras.Input(shape=(224, 224, 3)))\n",
        "model2.add(keras.layers.BatchNormalization())\n",
        "\n",
        "# remove first (input) layer\n",
        "# it's a functional layer which causes tensoflowjs to crash \n",
        "print(len(layers), len(layers[1:]))\n",
        "for layer in layers[1:]:\n",
        "  layer.trainable = False\n",
        "  model2.add(layer)\n",
        "\n",
        "model2.add(keras.layers.GlobalAveragePooling2D())\n",
        "model2.add(keras.layers.Dropout(0.2))\n",
        "model2.add(keras.layers.Dense(1, activation=\"selu\"))\n",
        "model2.load_weights(checkpoint_path)\n",
        "model2.build()\n",
        "model2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22 21\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization_1 (Batch (None, 224, 224, 3)       12        \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_1 ( (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 20,024,909\n",
            "Trainable params: 519\n",
            "Non-trainable params: 20,024,390\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvP3qIpSSB-7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b69c7fc7-7e07-4ee2-f94d-cad5a17bc071"
      },
      "source": [
        "start_1 = time.time()\n",
        "\n",
        "model2.compile(\n",
        "    optimizer=keras.optimizers.SGD(),\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 20 # sigmoid: 0.9441\n",
        "model2.fit(train2_ds, epochs=epochs, validation_data=val2_ds, callbacks=[cp_callback])\n",
        "\n",
        "print((time.time() - start_1) // 60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "    291/Unknown - 98s 336ms/step - loss: 0.4914 - binary_accuracy: 0.7556\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 113s 388ms/step - loss: 0.4914 - binary_accuracy: 0.7556 - val_loss: 0.3627 - val_binary_accuracy: 0.9067\n",
            "Epoch 2/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.3379 - binary_accuracy: 0.8927\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 111s 383ms/step - loss: 0.3379 - binary_accuracy: 0.8927 - val_loss: 0.2923 - val_binary_accuracy: 0.9381\n",
            "Epoch 3/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.2872 - binary_accuracy: 0.9197\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.2872 - binary_accuracy: 0.9197 - val_loss: 0.2557 - val_binary_accuracy: 0.9407\n",
            "Epoch 4/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.2575 - binary_accuracy: 0.9308\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 111s 382ms/step - loss: 0.2575 - binary_accuracy: 0.9308 - val_loss: 0.2330 - val_binary_accuracy: 0.9549\n",
            "Epoch 5/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.2392 - binary_accuracy: 0.9380\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 111s 383ms/step - loss: 0.2392 - binary_accuracy: 0.9380 - val_loss: 0.2174 - val_binary_accuracy: 0.9583\n",
            "Epoch 6/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.2261 - binary_accuracy: 0.9425\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.2261 - binary_accuracy: 0.9425 - val_loss: 0.2055 - val_binary_accuracy: 0.9579\n",
            "Epoch 7/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.2158 - binary_accuracy: 0.9436\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 383ms/step - loss: 0.2158 - binary_accuracy: 0.9436 - val_loss: 0.1964 - val_binary_accuracy: 0.9630\n",
            "Epoch 8/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.2065 - binary_accuracy: 0.9496\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 111s 383ms/step - loss: 0.2065 - binary_accuracy: 0.9496 - val_loss: 0.1892 - val_binary_accuracy: 0.9652\n",
            "Epoch 9/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.2002 - binary_accuracy: 0.9496\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.2002 - binary_accuracy: 0.9496 - val_loss: 0.1834 - val_binary_accuracy: 0.9673\n",
            "Epoch 10/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1958 - binary_accuracy: 0.9512\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.1958 - binary_accuracy: 0.9512 - val_loss: 0.1799 - val_binary_accuracy: 0.9721\n",
            "Epoch 11/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1914 - binary_accuracy: 0.9533\n",
            "Epoch 00011: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.1914 - binary_accuracy: 0.9533 - val_loss: 0.1738 - val_binary_accuracy: 0.9686\n",
            "Epoch 12/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1862 - binary_accuracy: 0.9562\n",
            "Epoch 00012: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.1862 - binary_accuracy: 0.9562 - val_loss: 0.1705 - val_binary_accuracy: 0.9721\n",
            "Epoch 13/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1827 - binary_accuracy: 0.9574\n",
            "Epoch 00013: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 383ms/step - loss: 0.1827 - binary_accuracy: 0.9574 - val_loss: 0.1674 - val_binary_accuracy: 0.9725\n",
            "Epoch 14/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1814 - binary_accuracy: 0.9557\n",
            "Epoch 00014: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 383ms/step - loss: 0.1814 - binary_accuracy: 0.9557 - val_loss: 0.1651 - val_binary_accuracy: 0.9742\n",
            "Epoch 15/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1767 - binary_accuracy: 0.9572\n",
            "Epoch 00015: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.1767 - binary_accuracy: 0.9572 - val_loss: 0.1620 - val_binary_accuracy: 0.9738\n",
            "Epoch 16/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1747 - binary_accuracy: 0.9579\n",
            "Epoch 00016: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.1747 - binary_accuracy: 0.9579 - val_loss: 0.1592 - val_binary_accuracy: 0.9738\n",
            "Epoch 17/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1733 - binary_accuracy: 0.9599\n",
            "Epoch 00017: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.1733 - binary_accuracy: 0.9599 - val_loss: 0.1580 - val_binary_accuracy: 0.9738\n",
            "Epoch 18/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1691 - binary_accuracy: 0.9605\n",
            "Epoch 00018: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.1691 - binary_accuracy: 0.9605 - val_loss: 0.1556 - val_binary_accuracy: 0.9746\n",
            "Epoch 19/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1679 - binary_accuracy: 0.9614\n",
            "Epoch 00019: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 383ms/step - loss: 0.1679 - binary_accuracy: 0.9614 - val_loss: 0.1541 - val_binary_accuracy: 0.9738\n",
            "Epoch 20/20\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1675 - binary_accuracy: 0.9603\n",
            "Epoch 00020: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 112s 384ms/step - loss: 0.1675 - binary_accuracy: 0.9603 - val_loss: 0.1528 - val_binary_accuracy: 0.9746\n",
            "37.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU93GglbbuOd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 768
        },
        "outputId": "10866f29-c8f2-49a3-9ece-ee5c312b4afd"
      },
      "source": [
        "start_2 = time.time()\n",
        "\n",
        "for lyr in model2.layers[2:23]:\n",
        "  lyr.trainable = True\n",
        "\n",
        "# It's important to recompile the model after making any changes to the\n",
        "# `trainable` attribute of any inner layer, so that changes are taken into account\n",
        "model2.compile(\n",
        "    optimizer=keras.optimizers.SGD(1e-5),  # Low learning rate\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=[keras.metrics.BinaryAccuracy()],\n",
        ")\n",
        "\n",
        "epochs = 10\n",
        "model2.fit(train2_ds, epochs=epochs, validation_data=val2_ds, callbacks=[cp_callback])\n",
        "print((time.time() - start_2) // 60)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "      2/Unknown - 1s 462ms/step - loss: 0.1374 - binary_accuracy: 0.9688WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2810s vs `on_train_batch_end` time: 0.6323s). Check your callbacks.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2810s vs `on_train_batch_end` time: 0.6323s). Check your callbacks.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "    291/Unknown - 274s 940ms/step - loss: 0.1507 - binary_accuracy: 0.9686\n",
            "Epoch 00001: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 297s 1s/step - loss: 0.1507 - binary_accuracy: 0.9686 - val_loss: 0.1395 - val_binary_accuracy: 0.9776\n",
            "Epoch 2/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1475 - binary_accuracy: 0.9690\n",
            "Epoch 00002: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 286s 982ms/step - loss: 0.1475 - binary_accuracy: 0.9690 - val_loss: 0.1387 - val_binary_accuracy: 0.9776\n",
            "Epoch 3/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1469 - binary_accuracy: 0.9701\n",
            "Epoch 00003: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 285s 979ms/step - loss: 0.1469 - binary_accuracy: 0.9701 - val_loss: 0.1379 - val_binary_accuracy: 0.9776\n",
            "Epoch 4/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1457 - binary_accuracy: 0.9714\n",
            "Epoch 00004: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 285s 979ms/step - loss: 0.1457 - binary_accuracy: 0.9714 - val_loss: 0.1372 - val_binary_accuracy: 0.9776\n",
            "Epoch 5/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1474 - binary_accuracy: 0.9698\n",
            "Epoch 00005: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 285s 979ms/step - loss: 0.1474 - binary_accuracy: 0.9698 - val_loss: 0.1365 - val_binary_accuracy: 0.9776\n",
            "Epoch 6/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1471 - binary_accuracy: 0.9694\n",
            "Epoch 00006: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 285s 979ms/step - loss: 0.1471 - binary_accuracy: 0.9694 - val_loss: 0.1359 - val_binary_accuracy: 0.9776\n",
            "Epoch 7/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1454 - binary_accuracy: 0.9711\n",
            "Epoch 00007: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 285s 979ms/step - loss: 0.1454 - binary_accuracy: 0.9711 - val_loss: 0.1353 - val_binary_accuracy: 0.9776\n",
            "Epoch 8/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1432 - binary_accuracy: 0.9717\n",
            "Epoch 00008: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 285s 979ms/step - loss: 0.1432 - binary_accuracy: 0.9717 - val_loss: 0.1348 - val_binary_accuracy: 0.9776\n",
            "Epoch 9/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1438 - binary_accuracy: 0.9701\n",
            "Epoch 00009: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 285s 979ms/step - loss: 0.1438 - binary_accuracy: 0.9701 - val_loss: 0.1342 - val_binary_accuracy: 0.9785\n",
            "Epoch 10/10\n",
            "291/291 [==============================] - ETA: 0s - loss: 0.1428 - binary_accuracy: 0.9708\n",
            "Epoch 00010: saving model to /content/gdrive/My Drive/colab/training_2/cp.ckpt\n",
            "291/291 [==============================] - 285s 980ms/step - loss: 0.1428 - binary_accuracy: 0.9708 - val_loss: 0.1337 - val_binary_accuracy: 0.9785\n",
            "47.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhKt_BK5V4GX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "b652e16b-0715-4992-ae5b-ddbc56d877d6"
      },
      "source": [
        "image_batch, label_batch = test2_ds.as_numpy_iterator().next()\n",
        "predictions = model2.predict(image_batch).flatten()\n",
        "# predictions = tf.where(predictions < 0.5, 0, 1)\n",
        "print(f'{label_batch}: Labels')\n",
        "print(f'{predictions}: Predictions')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0]: Labels\n",
            "[-1.7512559   7.5966434  14.456075    8.774034    1.9429191   5.5053253\n",
            "  0.98495924  3.9802139  -1.7439785   6.799868   -1.6845     16.236485\n",
            " -1.7520068  -1.7572677  -1.7299792   1.4699501  -1.7503388  14.003305\n",
            " -1.7563033   4.27554     9.00075     8.491771   -1.7508816  -1.7473652\n",
            " -1.7457969  -1.7578459  -1.7575895  -1.5759106  -1.3535689  -1.730011\n",
            "  8.585855   -1.7567315 ]: Predictions\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhlm9ZFqEiFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "d59b8f78-e5c3-48d1-cd88-d9216935669e"
      },
      "source": [
        "funcs = {\n",
        "    \"selu\": tf.nn.selu,\n",
        "    \"relu\": tf.nn.relu,\n",
        "    \"relu6\": tf.nn.relu6,\n",
        "    \"elu\": tf.nn.elu,\n",
        "    #\"swish\": tf.nn.swish,\n",
        "    \"leaky-relu\": tf.nn.leaky_relu,\n",
        "    #\"sigmoid\": tf.nn.sigmoid,\n",
        "    #\"softsign\": tf.nn.softsign,\n",
        "    # not applicable: \n",
        "    #\"crelu\": tf.nn.crelu,\n",
        "    #\"softmax\": tf.nn.softmax,\n",
        "    #\"log_softmax\": tf.nn.log_softmax,\n",
        "}\n",
        "\n",
        "image_batch, label_batch = test2_ds.as_numpy_iterator().next()\n",
        "predictions = model2.predict(image_batch).flatten()\n",
        "predictions = tf.convert_to_tensor(predictions)\n",
        "print(f'{label_batch}: Labels')\n",
        "\n",
        "for func in funcs.keys():\n",
        "    function = funcs[func]\n",
        "    predictions1 = function(predictions)\n",
        "    predictions1 = tf.where(predictions1 < 0.5, 0, 1)\n",
        "    print(f'{predictions1.numpy()}: Predictions {func}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0]: Labels\n",
            "[0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0]: Predictions selu\n",
            "[0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0]: Predictions relu\n",
            "[0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0]: Predictions relu6\n",
            "[0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0]: Predictions elu\n",
            "[0 1 1 1 1 1 1 1 0 1 0 1 0 0 0 1 0 1 0 1 1 1 0 0 0 0 0 0 0 0 1 0]: Predictions leaky-relu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbgr5FG2EmAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names=['cat','dog']\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    \"/Users/natalie/Downloads/iu-4.jpeg\", target_size=(150,150)\n",
        ")\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)\n",
        "\n",
        "predictions = model.predict(img_array, steps=1)\n",
        "predictions = tf.nn.sigmoid(predictions)\n",
        "predictions1 = tf.where(predictions < 0.5, 0, 1)\n",
        "print(class_names[predictions1.numpy()[0][0]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving model (for TFJS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBJhnfM0WUC0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "e6b4d9a6-4219-4465-c4a8-a2d016b079e2"
      },
      "source": [
        "!pip install tensorflowjs --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 71kB 6.3MB/s \n",
            "\u001b[K     |████████████████████████████████| 137.3MB 92kB/s \n",
            "\u001b[K     |████████████████████████████████| 92kB 12.7MB/s \n",
            "\u001b[K     |████████████████████████████████| 256kB 54.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 921kB 53.6MB/s \n",
            "\u001b[?25h  Building wheel for PyInquirer (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### should work, but doesn't"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ckH4M83PEM3Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "297ab61a-4583-4b73-ce71-f70501514508"
      },
      "source": [
        "import tensorflowjs as tfjs\n",
        "\n",
        "tfjs.converters.save_keras_model(model2, \"/content/gdrive/My Drive/colab/training_2/tfjs_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflowjs/converters/keras_h5_conversion.py:123: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  return h5py.File(h5file)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeA_ljoNMRI9",
        "colab_type": "text"
      },
      "source": [
        "### Finally the right way\n",
        "\n",
        "follow the solution of this guy: https://github.com/tensorflow/tfjs/issues/3772#issuecomment-672195520"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJjvBFRYFO2m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save('/content/gdrive/My Drive/colab/test.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}